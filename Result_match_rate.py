import pandas as pd
from neo4j import GraphDatabase
from tqdm import tqdm
import re
import signal
import collections
from config_sean import NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD

# ==============================================================================
# 1. ì„¤ì •
# ==============================================================================
FETCH_LIMIT = 10000
QUERY_TIMEOUT = 10

qachain_csv = "/cluster/pixstor/xudong-lab/yongfang/fatplants_cypher/sean/evaluation/pathway_evaluation_complete_with_result_QAChain.csv"
my_best_csv = "/cluster/pixstor/xudong-lab/yongfang/fatplants_cypher/sean/evaluation/pathway_evaluation_complete_with_result.csv"
output_report_csv = "evaluation_report.csv" 

# ==============================================================================
# 2. ìœ í‹¸ë¦¬í‹° (V6.0 í•µì‹¬ ë¡œì§ ìœ ì§€)
# ==============================================================================
class TimeoutException(Exception): pass
def timeout_handler(signum, frame): raise TimeoutException("Timeout")

def unwrap_count_query(query):
    if not isinstance(query, str): return query
    if "count(" not in query.lower(): return None
    return re.sub(r'count\s*\(\s*(.*?)\s*\)', r'\1', query, flags=re.IGNORECASE)

def clean_cypher(q):
    if not isinstance(q, str): return ""
    q = re.sub(r'```(?:cypher)?', '', q, flags=re.IGNORECASE)
    q = q.strip().strip('`').strip("'").strip('"')
    return q

def extract_ids_from_record(record_values):
    extracted = set()
    def recursive_extract(item):
        if hasattr(item, 'items') or isinstance(item, dict):
            d = dict(item)
            for key in ['id', 'name', 'title', 'symbol']:
                if key in d: extracted.add(str(d[key]))
            if not extracted: extracted.add(str(sorted(d.items())))
        elif isinstance(item, list):
            for sub in item: recursive_extract(sub)
        else:
            extracted.add(str(item))
    for val in record_values: recursive_extract(val)
    return extracted

# ==============================================================================
# 3. ì‹¤í–‰ ë¡œì§ (íƒ€ì„ì•„ì›ƒ ì ìš©)
# ==============================================================================
def run_query_and_fetch(session, query):
    clean_q = clean_cypher(query)
    if not clean_q: return None, "Empty"
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(QUERY_TIMEOUT)
    try:
        result = session.run(clean_q)
        data = [record.values() for record in result]
        signal.alarm(0)
        return data, "Success"
    except TimeoutException:
        return None, "Timeout"
    except Exception as e:
        signal.alarm(0)
        return None, f"Error: {str(e)}"

# ==============================================================================
# 4. ì±„ì  ë° ë¶„ì„ ë¡œì§ (V6.0 Deep Subset ë™ì¼ ì ìš©)
# ==============================================================================
def is_deep_subset(subset_data, superset_data):
    if not subset_data: return True 
    if not superset_data: return False
    
    sub_sets = [extract_ids_from_record(r) for r in subset_data]
    super_sets = [extract_ids_from_record(r) for r in superset_data]
    
    for sub in sub_sets:
        if not sub: continue
        match_found = False
        for sup in super_sets:
            if not sub.isdisjoint(sup):
                match_found = True
                break
        if not match_found: return False
    return True

def analyze_and_score(session, gt_query, bot_query):
    report = {
        "is_correct": False,
        "match_type": "Mismatch",
        "gt_count": 0, "bot_count": 0,
        "missing_examples": "", "extra_examples": ""
    }
    
    # 1. ì‹¤í–‰
    gt_res, gt_msg = run_query_and_fetch(session, gt_query)
    bot_res, bot_msg = run_query_and_fetch(session, bot_query)
    
    if gt_res is None: 
        report["match_type"] = f"GT Error: {gt_msg}"
        return report
    if bot_res is None:
        report["match_type"] = f"Bot Error: {bot_msg}"
        return report

    report["gt_count"] = len(gt_res)
    report["bot_count"] = len(bot_res)

    # 2. Deep Inspection (Count -> List ë³€í™˜)
    final_gt_res = gt_res
    final_bot_res = bot_res
    
    gt_list_query = unwrap_count_query(gt_query)
    bot_list_query = unwrap_count_query(bot_query)
    
    if gt_list_query or bot_list_query:
        q1 = gt_list_query if gt_list_query else gt_query
        q2 = bot_list_query if bot_list_query else bot_query
        
        deep_gt, _ = run_query_and_fetch(session, q1)
        deep_bot, _ = run_query_and_fetch(session, q2)
        
        if deep_gt is not None and deep_bot is not None:
            final_gt_res = deep_gt
            final_bot_res = deep_bot

    # 3. ì±„ì  (V6.0 Logic)
    is_subset = is_deep_subset(final_bot_res, final_gt_res)
    is_superset = is_deep_subset(final_gt_res, final_bot_res)
    
    if is_subset or is_superset:
        report["is_correct"] = True
        if is_subset and is_superset:
            report["match_type"] = "Full Match"
        else:
            report["match_type"] = "Subset Match"
            
    if not final_gt_res and not final_bot_res:
        report["is_correct"] = True
        report["match_type"] = "Empty Match"

    # ìˆ«ì ì •í™• ì¼ì¹˜ ë³´ë„ˆìŠ¤
    if not report["is_correct"]:
        if len(gt_res) == 1 and len(bot_res) == 1 and isinstance(gt_res[0][0], (int, float)):
             if gt_res[0][0] == bot_res[0][0]:
                 report["is_correct"] = True
                 report["match_type"] = "Count Exact Match"
             else:
                 report["match_type"] = "Count Mismatch"

    # 4. ë¶„ì„ ë°ì´í„° ìƒì„± (ë¦¬í¬íŠ¸ìš©)
    gt_ids_list = [extract_ids_from_record(r) for r in final_gt_res]
    bot_ids_list = [extract_ids_from_record(r) for r in final_bot_res]
    all_gt_ids = set().union(*gt_ids_list)
    all_bot_ids = set().union(*bot_ids_list)
    
    report["missing_examples"] = str(list(all_gt_ids - all_bot_ids)[:3])
    report["extra_examples"] = str(list(all_bot_ids - all_gt_ids)[:3])
    
    return report

# ==============================================================================
# 5. ë©”ì¸ ì‹¤í–‰ ë° í¬ë§·íŒ… ì¶œë ¥
# ==============================================================================
if __name__ == "__main__":
    print(f"ğŸ”Œ Neo4j ì—°ê²°: {NEO4J_URI}")
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

    try:
        df_qa = pd.read_csv(qachain_csv)
        df_my = pd.read_csv(my_best_csv)
        df_qa.columns = df_qa.columns.str.strip()
        df_my.columns = df_my.columns.str.strip()
        if 'cypher_executable' in df_qa.columns: df_qa = df_qa.rename(columns={'cypher_executable': 'truth'})
        merged = pd.merge(df_qa, df_my, on='question', how='inner', suffixes=('_qa', '_my'))
        print(f"âœ… ì´ {len(merged)}ê°œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
    except: exit()

    results_data = []
    stats = { "valid": 0, "gt_fail": 0, "lipidbot": 0, "qachain": 0 }
    match_types = collections.Counter()

    print("\nğŸš€ [V7.0 Final Evaluation] ì±„ì  ì‹œì‘...")
    
    with driver.session() as session:
        for idx, row in tqdm(merged.iterrows(), total=len(merged)):
            truth = str(row.get('truth', row.get('truth_qa', '')))
            my_cypher = str(row.get('generated_cypher_my', row.get('generated_cypher', '')))
            qa_cypher = str(row.get('QAChain', ''))
            
            my_report = analyze_and_score(session, truth, my_cypher)
            
            if "GT Error" in my_report["match_type"]:
                stats["gt_fail"] += 1
                status_str = "Invalid (GT Error)"
            else:
                stats["valid"] += 1
                match_types[my_report["match_type"]] += 1
                
                if my_report["is_correct"]: 
                    stats["lipidbot"] += 1
                    status_str = "âœ… Correct"
                else:
                    status_str = "âŒ Incorrect"
                
                # QAChain ë¹„êµìš© (í†µê³„ë§Œ)
                qa_report = analyze_and_score(session, truth, qa_cypher)
                if qa_report["is_correct"]: stats["qachain"] += 1

            # [CSV ê°•í™”] ë³´ê¸° ì¢‹ì€ í¬ë§·ìœ¼ë¡œ ì €ì¥
            results_data.append({
                "Result": status_str,
                "Reason (Match Type)": my_report["match_type"],
                "Counts (Bot / GT)": f"{my_report['bot_count']} / {my_report['gt_count']}",
                "Missing IDs (Example)": my_report["missing_examples"] if my_report["missing_examples"] != "[]" else "-",
                "Extra IDs (Example)": my_report["extra_examples"] if my_report["extra_examples"] != "[]" else "-",
                "Question": row['question'],
                "Bot Query": my_cypher,
                "Truth Query": truth
            })

    driver.close()

    # CSV ì €ì¥
    # ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì¹˜
    cols = ["Result", "Reason (Match Type)", "Counts (Bot / GT)", "Missing IDs (Example)", "Extra IDs (Example)", "Question", "Bot Query", "Truth Query"]
    pd.DataFrame(results_data)[cols].to_csv(output_report_csv, index=False)
    
    # ----------------------------------------------------------------------
    # [Prettier Console Output] ìµœì¢… ê²°ê³¼ í™”ë©´ ì¶œë ¥
    # ----------------------------------------------------------------------
    def pct(n): return (n / stats["valid"] * 100) if stats["valid"] > 0 else 0
    
    print("\n" + "="*80)
    print(" ğŸ“Š FINAL PERFORMANCE DASHBOARD")
    print("="*80)
    print(" [Data Summary]")
    print(f"  â€¢ ì´ ë¬¸ì œ ìˆ˜      : {len(merged)}")
    print(f"  â€¢ âŒ ë¬´íš¨(GT Error): {stats['gt_fail']} (ì œì™¸ë¨)")
    print(f"  â€¢ âœ… ìœ íš¨(Valid)   : {stats['valid']} (ì±„ì  ëŒ€ìƒ)")
    print("")
    print(" [Accuracy Ranking]")
    print(f"  ğŸ¥‡ LipidBot      : {pct(stats['lipidbot']):.1f}% ({stats['lipidbot']} / {stats['valid']}) ğŸš€")
    print(f"  ğŸ¥ˆ CypherQAChain : {pct(stats['qachain']):.1f}% ({stats['qachain']} / {stats['valid']})")
    print("")
    print(" [Match Details (LipidBot Analysis)]")
    total_correct = stats['lipidbot']
    total_incorrect = stats['valid'] - total_correct
    
    # ì •ë‹µ ìœ í˜•ë³„ í†µê³„
    print(f"  â€¢ ğŸŸ¢ Full/Perfect Match : {match_types['Full Match']} ({match_types['Full Match']/stats['valid']*100:.1f}%)")
    print(f"  â€¢ ğŸŸ¡ Subset Match (ë¶€ë¶„) : {match_types['Subset Match']} ({match_types['Subset Match']/stats['valid']*100:.1f}%)")
    print(f"  â€¢ âšª Empty Match (ê³µí†µì—†ìŒ): {match_types['Empty Match']} ({match_types['Empty Match']/stats['valid']*100:.1f}%)")
    print(f"  â€¢ ğŸ”µ Count Exact Match  : {match_types['Count Exact Match']}")
    print("-" * 40)
    print(f"  â€¢ ğŸ”´ Failures (Mismatch) : {total_incorrect} ({total_incorrect/stats['valid']*100:.1f}%)")
    print("="*80)
    print(f"ğŸ’¾ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: '{output_report_csv}'")